{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import the necessary libraries, modules, Datasets","metadata":{}},{"cell_type":"markdown","source":"## Import Libraries and mModules","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport transformers\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T12:08:09.030668Z","iopub.execute_input":"2025-12-27T12:08:09.030995Z","iopub.status.idle":"2025-12-27T12:08:09.653092Z","shell.execute_reply.started":"2025-12-27T12:08:09.030965Z","shell.execute_reply":"2025-12-27T12:08:09.652522Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Import Dataset\n","metadata":{}},{"cell_type":"code","source":"df_labeled = pd.read_parquet(\"hf://datasets/qiaojin/PubMedQA/pqa_labeled/train-00000-of-00001.parquet\")\ndf_artificial = pd.read_parquet(\"hf://datasets/qiaojin/PubMedQA/pqa_artificial/train-00000-of-00001.parquet\")\ndf_unlabeled = pd.read_parquet(\"hf://datasets/qiaojin/PubMedQA/pqa_unlabeled/train-00000-of-00001.parquet\")\n\n#Add final_answer column to the unlabeled dataset\ndf_unlabeled[\"final_decision\"]=None\n\ndf=pd.concat([df_labeled, df_artificial, df_unlabeled], ignore_index=True)\n\nprint(f\"Labled Shape: {df_labeled.shape}\")\nprint(f\"Artificial Shape: {df_artificial.shape}\")\nprint(f\"Unlabled: {df_unlabeled.shape}\")\nprint(f\"Combined Shape: {df.shape}\")\n\nprint(df.info())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:42:05.931604Z","iopub.execute_input":"2025-12-27T11:42:05.932164Z","iopub.status.idle":"2025-12-27T11:42:10.838287Z","shell.execute_reply.started":"2025-12-27T11:42:05.932133Z","shell.execute_reply":"2025-12-27T11:42:10.837579Z"}},"outputs":[{"name":"stdout","text":"Labled Shape: (1000, 5)\nArtificial Shape: (211269, 5)\nUnlabled: (61249, 5)\nCombined Shape: (273518, 5)\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 273518 entries, 0 to 273517\nData columns (total 5 columns):\n #   Column          Non-Null Count   Dtype \n---  ------          --------------   ----- \n 0   pubid           273518 non-null  int32 \n 1   question        273518 non-null  object\n 2   context         273518 non-null  object\n 3   long_answer     273518 non-null  object\n 4   final_decision  212269 non-null  object\ndtypes: int32(1), object(4)\nmemory usage: 9.4+ MB\nNone\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Split Dataset into test and train","metadata":{}},{"cell_type":"markdown","source":"### First split the dataframe into train and test","metadata":{}},{"cell_type":"code","source":"train_set, test_set=train_test_split(df, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T12:08:18.381287Z","iopub.execute_input":"2025-12-27T12:08:18.382128Z","iopub.status.idle":"2025-12-27T12:08:18.471385Z","shell.execute_reply.started":"2025-12-27T12:08:18.382097Z","shell.execute_reply":"2025-12-27T12:08:18.470527Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"print(f\"Training Set Rows: {train_set.shape}\")\nprint(f\"Test Set Rows: {test_set.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T12:10:13.254832Z","iopub.execute_input":"2025-12-27T12:10:13.255134Z","iopub.status.idle":"2025-12-27T12:10:13.259399Z","shell.execute_reply.started":"2025-12-27T12:10:13.255105Z","shell.execute_reply":"2025-12-27T12:10:13.258636Z"}},"outputs":[{"name":"stdout","text":"Training Set Rows: (218814, 5)\nTest Set Rows: (54704, 5)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### Flatten the dataset\n* Currently the column in the datset looks like this(a dictionary with keys-contexts, lables, meshes:\n    {\n    'contexts': [\n        \"Use of aspirin is common.\",          # Sentence 1\n        \"We studied 500 patients.\",           # Sentence 2\n        \"Results showed reduced pain.\"        # Sentence 3\n    ],\n    'labels': [\"BACKGROUND\", \"METHODS\", \"RESULTS\"],\n    'meshes': [\"Aspirin\", \"Pain\"]\n\n * We will check if each row contains a key called contexts and if it does we will will join every sentence from the contexts into a single space separated text","metadata":{}},{"cell_type":"code","source":"def flatten_context(row):\n    if isinstance(row['context'], dict) and 'contexts' in row['context']:\n        return \" \".join(row['context']['contexts'])\n\n    return \"\"\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T12:16:44.328075Z","iopub.execute_input":"2025-12-27T12:16:44.328394Z","iopub.status.idle":"2025-12-27T12:16:44.332899Z","shell.execute_reply.started":"2025-12-27T12:16:44.328351Z","shell.execute_reply":"2025-12-27T12:16:44.332124Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"* We will apply the flatten_context function to every row in the train set and test set\n* We apply it to test set also just for uniformity sake.\n* We also create/use the .copy() function to break the test_set and train_set links from the original datafram(df)","metadata":{}},{"cell_type":"code","source":"train_set=train_set.copy()\ntrain_set['full_text']=train_set.apply(flatten_context, axis=1)\n\ntest_set=test_set.copy()\ntest_set['full_text']=test_set.apply(flatten_context, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T12:22:31.457544Z","iopub.execute_input":"2025-12-27T12:22:31.458307Z","iopub.status.idle":"2025-12-27T12:22:34.841695Z","shell.execute_reply.started":"2025-12-27T12:22:31.458276Z","shell.execute_reply":"2025-12-27T12:22:34.841076Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"print(train_set.info())\nprint(f\"No of unique pubids: {train_set['pubid'].nunique()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T12:37:03.093600Z","iopub.execute_input":"2025-12-27T12:37:03.094352Z","iopub.status.idle":"2025-12-27T12:37:03.239664Z","shell.execute_reply.started":"2025-12-27T12:37:03.094316Z","shell.execute_reply":"2025-12-27T12:37:03.238894Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 218814 entries, 141060 to 121958\nData columns (total 6 columns):\n #   Column          Non-Null Count   Dtype \n---  ------          --------------   ----- \n 0   pubid           218814 non-null  int32 \n 1   question        218814 non-null  object\n 2   context         218814 non-null  object\n 3   long_answer     218814 non-null  object\n 4   final_decision  169916 non-null  object\n 5   full_text       218814 non-null  object\ndtypes: int32(1), object(5)\nmemory usage: 10.9+ MB\nNone\nNo of unique pubids: 218814\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"train_set.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T12:34:37.660338Z","iopub.execute_input":"2025-12-27T12:34:37.661072Z","iopub.status.idle":"2025-12-27T12:34:37.681404Z","shell.execute_reply.started":"2025-12-27T12:34:37.661029Z","shell.execute_reply":"2025-12-27T12:34:37.680855Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"           pubid                                           question  \\\n141060  23356518  Do magnolia polyphenols attenuate oxidative an...   \n101826  25476117  Are olfactory identification deficits at ident...   \n39223   18289138  Are no differences seen in the regional cerebr...   \n42170   21725797  Does proton pump inhibitor prophylaxis increas...   \n104449  23731765  Does smooth muscle cell transplantation improv...   \n\n                                                  context  \\\n141060  {'contexts': ['The bark of magnolia has been u...   \n101826  {'contexts': ['We have previously reported tha...   \n39223   {'contexts': ['Anorexia nervosa (AN) is subdiv...   \n42170   {'contexts': ['Stress-related mucosal damage i...   \n104449  {'contexts': ['Damage to smooth muscle has bee...   \n\n                                              long_answer final_decision  \\\n141060  This study highlights the important role of NA...            yes   \n101826  These results suggest that impaired OI is not ...            yes   \n39223   Abnormalities of the neuronal circuits contain...            yes   \n42170   The use of a PPI as a prophylactic treatment a...            yes   \n104449  During the 2-week follow-up period after trans...            yes   \n\n                                                full_text  \n141060  The bark of magnolia has been used in Oriental...  \n101826  We have previously reported that olfactory ide...  \n39223   Anorexia nervosa (AN) is subdivided into the r...  \n42170   Stress-related mucosal damage is an erosive pr...  \n104449  Damage to smooth muscle has been the primary c...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pubid</th>\n      <th>question</th>\n      <th>context</th>\n      <th>long_answer</th>\n      <th>final_decision</th>\n      <th>full_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>141060</th>\n      <td>23356518</td>\n      <td>Do magnolia polyphenols attenuate oxidative an...</td>\n      <td>{'contexts': ['The bark of magnolia has been u...</td>\n      <td>This study highlights the important role of NA...</td>\n      <td>yes</td>\n      <td>The bark of magnolia has been used in Oriental...</td>\n    </tr>\n    <tr>\n      <th>101826</th>\n      <td>25476117</td>\n      <td>Are olfactory identification deficits at ident...</td>\n      <td>{'contexts': ['We have previously reported tha...</td>\n      <td>These results suggest that impaired OI is not ...</td>\n      <td>yes</td>\n      <td>We have previously reported that olfactory ide...</td>\n    </tr>\n    <tr>\n      <th>39223</th>\n      <td>18289138</td>\n      <td>Are no differences seen in the regional cerebr...</td>\n      <td>{'contexts': ['Anorexia nervosa (AN) is subdiv...</td>\n      <td>Abnormalities of the neuronal circuits contain...</td>\n      <td>yes</td>\n      <td>Anorexia nervosa (AN) is subdivided into the r...</td>\n    </tr>\n    <tr>\n      <th>42170</th>\n      <td>21725797</td>\n      <td>Does proton pump inhibitor prophylaxis increas...</td>\n      <td>{'contexts': ['Stress-related mucosal damage i...</td>\n      <td>The use of a PPI as a prophylactic treatment a...</td>\n      <td>yes</td>\n      <td>Stress-related mucosal damage is an erosive pr...</td>\n    </tr>\n    <tr>\n      <th>104449</th>\n      <td>23731765</td>\n      <td>Does smooth muscle cell transplantation improv...</td>\n      <td>{'contexts': ['Damage to smooth muscle has bee...</td>\n      <td>During the 2-week follow-up period after trans...</td>\n      <td>yes</td>\n      <td>Damage to smooth muscle has been the primary c...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"# Chunking","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import AutoTokenizer\n\n# 1. Setup the Tokenizer (Using a fast standard one, or use your Llama tokenizer)\ntokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-m3\")\n\n# 2. Define the Chunking Function\ndef chunk_text_to_df(input_df, text_col='full_text', id_col='pubid', chunk_size=256, overlap=32):\n    all_chunks = []\n    \n    # Calculate the stride (how many tokens to move forward)\n    stride = chunk_size - overlap\n    \n    print(f\"Processing {len(input_df)} documents...\")\n    \n    for index, row in input_df.iterrows():\n        doc_id = row[id_col]\n        text = row[text_col]\n        \n        # Tokenize the entire text (return tensors='pt' is slower for loops, standard lists are fine here)\n        tokens = tokenizer.encode(text, add_special_tokens=False)\n        \n        # Create sliding window chunks\n        chunk_index = 0\n        for i in range(0, len(tokens), stride):\n            # Define the slice range\n            chunk_tokens = tokens[i : i + chunk_size]\n            \n            # Decode back to text\n            chunk_text = tokenizer.decode(chunk_tokens)\n            \n            # Create the unique chunk ID (e.g., doc_42_chunk_00)\n            chunk_id = f\"{doc_id}_chunk_{chunk_index:02d}\"\n            \n            # Append to list\n            all_chunks.append({\n                \"chunk_id\": chunk_id,\n                \"document_id\": doc_id,\n                \"chunk_index\": chunk_index,\n                \"chunk_text\": chunk_text\n            })\n            \n            chunk_index += 1\n            \n            # Stop if this was the last chunk (handling exact edge cases)\n            if i + chunk_size >= len(tokens):\n                break\n                \n    # Create the final DataFrame\n    return pd.DataFrame(all_chunks)\n\n# 3. Apply it to your existing 'train_set'\n# Ensure your train_set has 'full_text' and a unique ID column (like 'pubid')\n# If you don't have an ID column, create one first: train_set['pubid'] = train_set.index\n\nchunk_df = chunk_text_to_df(\n    train_set, \n    text_col='full_text', \n    id_col='pubid',  # Replace with your actual ID column name\n    chunk_size=256, \n    overlap=32\n)\n\n# 4. View the Result\nprint(chunk_df.head())\nprint(f\"Total chunks generated: {len(chunk_df)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T13:29:38.078916Z","iopub.execute_input":"2025-12-27T13:29:38.079237Z","iopub.status.idle":"2025-12-27T13:34:16.376296Z","shell.execute_reply.started":"2025-12-27T13:29:38.079208Z","shell.execute_reply":"2025-12-27T13:34:16.375476Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/444 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2be60c6646644e0c9b43e846fb61344b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15e76086a5d54b06b2a76b9b23bb5797"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"028b8e7f947a4df6b893faa6e67593b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"299bcf6624fe46dda9aa517884cf6ef9"}},"metadata":{}},{"name":"stdout","text":"Processing 218814 documents...\n            chunk_id  document_id  chunk_index  \\\n0  23356518_chunk_00     23356518            0   \n1  23356518_chunk_01     23356518            1   \n2  23356518_chunk_02     23356518            2   \n3  25476117_chunk_00     25476117            0   \n4  25476117_chunk_01     25476117            1   \n\n                                          chunk_text  \n0  The bark of magnolia has been used in Oriental...  \n1  (DHE) was used to assay superoxide production ...  \n2  ted IFNγ±LPS-induced iNOS expression, NO, and ...  \n3  We have previously reported that olfactory ide...  \n4  up between individuals with a diagnosis of sch...  \nTotal chunks generated: 421148\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## Save the chunked data to disk/working directory as HF Dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_from_disk\nfrom datasets import Dataset\nhf_chunk_df=Dataset.from_pandas(chunk_df)\n\n# 1. Save the dataset to the output directory\nsave_path = \"./chunked_data_v1\"\nhf_chunk_df.save_to_disk(save_path)\n\nprint(f\"✅ Dataset saved successfully to {save_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T13:46:01.969733Z","iopub.execute_input":"2025-12-27T13:46:01.970414Z","iopub.status.idle":"2025-12-27T13:46:04.941864Z","shell.execute_reply.started":"2025-12-27T13:46:01.970385Z","shell.execute_reply":"2025-12-27T13:46:04.941273Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/421148 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea74ecac82b845208bc11f2856708744"}},"metadata":{}},{"name":"stdout","text":"✅ Dataset saved successfully to ./chunked_data_v1\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"## Load the saved chunk tabe as a HF Dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_from_disk\nimport os\n\nsave_path = \"./chunked_data_v1\"\n\n# Check if file exists first to avoid errors\nif os.path.exists(save_path):\n    # Load it directly from disk (takes milliseconds)\n    hf_chunked_df = load_from_disk(save_path)\n    print(\"✅ Loaded dataset from disk!\")\n    \n    # Verify it looks right\n    print(hf_chunked_df)\nelse:\n    print(\"⚠️ No saved dataset found. You need to run the chunking code first.\")\n\nchunked_df=hf_chunked_df.to_pandas()\n\nprint(\"The dataframe looks like this: \")\nprint(chunked_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T13:54:48.925317Z","iopub.execute_input":"2025-12-27T13:54:48.925651Z","iopub.status.idle":"2025-12-27T13:54:49.490520Z","shell.execute_reply.started":"2025-12-27T13:54:48.925622Z","shell.execute_reply":"2025-12-27T13:54:49.489899Z"}},"outputs":[{"name":"stdout","text":"✅ Loaded dataset from disk!\nDataset({\n    features: ['chunk_id', 'document_id', 'chunk_index', 'chunk_text'],\n    num_rows: 421148\n})\nThe dataframe looks like this: \n                 chunk_id  document_id  chunk_index  \\\n0       23356518_chunk_00     23356518            0   \n1       23356518_chunk_01     23356518            1   \n2       23356518_chunk_02     23356518            2   \n3       25476117_chunk_00     25476117            0   \n4       25476117_chunk_01     25476117            1   \n...                   ...          ...          ...   \n421143  27011950_chunk_00     27011950            0   \n421144  20463894_chunk_00     20463894            0   \n421145  20463894_chunk_01     20463894            1   \n421146  19663554_chunk_00     19663554            0   \n421147  19663554_chunk_01     19663554            1   \n\n                                               chunk_text  \n0       The bark of magnolia has been used in Oriental...  \n1       (DHE) was used to assay superoxide production ...  \n2       ted IFNγ±LPS-induced iNOS expression, NO, and ...  \n3       We have previously reported that olfactory ide...  \n4       up between individuals with a diagnosis of sch...  \n...                                                   ...  \n421143  The goal of this study was to compare associat...  \n421144  Fusion of placental villous cytotrophoblasts w...  \n421145  control. Furthermore, caveolin-1 knockdown alo...  \n421146  Microelectrode recording (MER) and macrostimul...  \n421147  placement, Wilcoxon signed-rank tests were app...  \n\n[421148 rows x 4 columns]\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
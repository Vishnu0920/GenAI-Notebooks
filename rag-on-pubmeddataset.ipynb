{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14318667,"sourceType":"datasetVersion","datasetId":9140565}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import the necessary libraries, modules, Datasets","metadata":{}},{"cell_type":"markdown","source":"## Import Libraries and mModules","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport transformers\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T10:19:51.252613Z","iopub.execute_input":"2026-01-06T10:19:51.252939Z","iopub.status.idle":"2026-01-06T10:19:51.281188Z","shell.execute_reply.started":"2026-01-06T10:19:51.252911Z","shell.execute_reply":"2026-01-06T10:19:51.280530Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## Import Dataset\n","metadata":{}},{"cell_type":"code","source":"df_labeled = pd.read_parquet(\"hf://datasets/qiaojin/PubMedQA/pqa_labeled/train-00000-of-00001.parquet\")\ndf_artificial = pd.read_parquet(\"hf://datasets/qiaojin/PubMedQA/pqa_artificial/train-00000-of-00001.parquet\")\ndf_unlabeled = pd.read_parquet(\"hf://datasets/qiaojin/PubMedQA/pqa_unlabeled/train-00000-of-00001.parquet\")\n\n#Add final_answer column to the unlabeled dataset\ndf_unlabeled[\"final_decision\"]=None\n\ndf=pd.concat([df_labeled, df_artificial, df_unlabeled], ignore_index=True)\n\nprint(f\"Labled Shape: {df_labeled.shape}\")\nprint(f\"Artificial Shape: {df_artificial.shape}\")\nprint(f\"Unlabled: {df_unlabeled.shape}\")\nprint(f\"Combined Shape: {df.shape}\")\n\nprint(df.info())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T10:19:53.432875Z","iopub.execute_input":"2026-01-06T10:19:53.434366Z","iopub.status.idle":"2026-01-06T10:20:01.379156Z","shell.execute_reply.started":"2026-01-06T10:19:53.434334Z","shell.execute_reply":"2026-01-06T10:20:01.378461Z"}},"outputs":[{"name":"stdout","text":"Labled Shape: (1000, 5)\nArtificial Shape: (211269, 5)\nUnlabled: (61249, 5)\nCombined Shape: (273518, 5)\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 273518 entries, 0 to 273517\nData columns (total 5 columns):\n #   Column          Non-Null Count   Dtype \n---  ------          --------------   ----- \n 0   pubid           273518 non-null  int32 \n 1   question        273518 non-null  object\n 2   context         273518 non-null  object\n 3   long_answer     273518 non-null  object\n 4   final_decision  212269 non-null  object\ndtypes: int32(1), object(4)\nmemory usage: 9.4+ MB\nNone\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## Split Dataset into test and train","metadata":{}},{"cell_type":"markdown","source":"### First split the dataframe into train and test","metadata":{}},{"cell_type":"code","source":"train_set, test_set=train_test_split(df, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T10:20:11.937180Z","iopub.execute_input":"2026-01-06T10:20:11.937718Z","iopub.status.idle":"2026-01-06T10:20:12.030801Z","shell.execute_reply.started":"2026-01-06T10:20:11.937687Z","shell.execute_reply":"2026-01-06T10:20:12.030219Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"print(f\"Training Set Rows: {train_set.shape}\")\nprint(f\"Test Set Rows: {test_set.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T10:20:14.261462Z","iopub.execute_input":"2026-01-06T10:20:14.262347Z","iopub.status.idle":"2026-01-06T10:20:14.266323Z","shell.execute_reply.started":"2026-01-06T10:20:14.262316Z","shell.execute_reply":"2026-01-06T10:20:14.265629Z"}},"outputs":[{"name":"stdout","text":"Training Set Rows: (218814, 5)\nTest Set Rows: (54704, 5)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"### Flatten the dataset\n* Currently the column in the datset looks like this(a dictionary with keys-contexts, lables, meshes:\n    {\n    'contexts': [\n        \"Use of aspirin is common.\",          # Sentence 1\n        \"We studied 500 patients.\",           # Sentence 2\n        \"Results showed reduced pain.\"        # Sentence 3\n    ],\n    'labels': [\"BACKGROUND\", \"METHODS\", \"RESULTS\"],\n    'meshes': [\"Aspirin\", \"Pain\"]\n\n * We will check if each row contains a key called contexts and if it does we will will join every sentence from the contexts into a single space separated text","metadata":{}},{"cell_type":"code","source":"def flatten_context(row):\n    if isinstance(row['context'], dict) and 'contexts' in row['context']:\n        return \" \".join(row['context']['contexts'])\n\n    return \"\"\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T10:20:43.956423Z","iopub.execute_input":"2026-01-06T10:20:43.957023Z","iopub.status.idle":"2026-01-06T10:20:43.961095Z","shell.execute_reply.started":"2026-01-06T10:20:43.956992Z","shell.execute_reply":"2026-01-06T10:20:43.960381Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"* We will apply the flatten_context function to every row in the train set and test set\n* We apply it to test set also just for uniformity sake.\n* We also create/use the .copy() function to break the test_set and train_set links from the original datafram(df)","metadata":{}},{"cell_type":"code","source":"train_set=train_set.copy()\ntrain_set['full_text']=train_set.apply(flatten_context, axis=1)\n\ntest_set=test_set.copy()\ntest_set['full_text']=test_set.apply(flatten_context, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T10:20:48.326891Z","iopub.execute_input":"2026-01-06T10:20:48.327206Z","iopub.status.idle":"2026-01-06T10:20:51.657867Z","shell.execute_reply.started":"2026-01-06T10:20:48.327180Z","shell.execute_reply":"2026-01-06T10:20:51.657074Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"print(train_set.info())\nprint(f\"No of unique pubids: {train_set['pubid'].nunique()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T10:20:55.438387Z","iopub.execute_input":"2026-01-06T10:20:55.438692Z","iopub.status.idle":"2026-01-06T10:20:55.578733Z","shell.execute_reply.started":"2026-01-06T10:20:55.438664Z","shell.execute_reply":"2026-01-06T10:20:55.578140Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 218814 entries, 141060 to 121958\nData columns (total 6 columns):\n #   Column          Non-Null Count   Dtype \n---  ------          --------------   ----- \n 0   pubid           218814 non-null  int32 \n 1   question        218814 non-null  object\n 2   context         218814 non-null  object\n 3   long_answer     218814 non-null  object\n 4   final_decision  169916 non-null  object\n 5   full_text       218814 non-null  object\ndtypes: int32(1), object(5)\nmemory usage: 10.9+ MB\nNone\nNo of unique pubids: 218814\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"train_set.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T10:20:59.195494Z","iopub.execute_input":"2026-01-06T10:20:59.196053Z","iopub.status.idle":"2026-01-06T10:20:59.215961Z","shell.execute_reply.started":"2026-01-06T10:20:59.196022Z","shell.execute_reply":"2026-01-06T10:20:59.215374Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"           pubid                                           question  \\\n141060  23356518  Do magnolia polyphenols attenuate oxidative an...   \n101826  25476117  Are olfactory identification deficits at ident...   \n39223   18289138  Are no differences seen in the regional cerebr...   \n42170   21725797  Does proton pump inhibitor prophylaxis increas...   \n104449  23731765  Does smooth muscle cell transplantation improv...   \n\n                                                  context  \\\n141060  {'contexts': ['The bark of magnolia has been u...   \n101826  {'contexts': ['We have previously reported tha...   \n39223   {'contexts': ['Anorexia nervosa (AN) is subdiv...   \n42170   {'contexts': ['Stress-related mucosal damage i...   \n104449  {'contexts': ['Damage to smooth muscle has bee...   \n\n                                              long_answer final_decision  \\\n141060  This study highlights the important role of NA...            yes   \n101826  These results suggest that impaired OI is not ...            yes   \n39223   Abnormalities of the neuronal circuits contain...            yes   \n42170   The use of a PPI as a prophylactic treatment a...            yes   \n104449  During the 2-week follow-up period after trans...            yes   \n\n                                                full_text  \n141060  The bark of magnolia has been used in Oriental...  \n101826  We have previously reported that olfactory ide...  \n39223   Anorexia nervosa (AN) is subdivided into the r...  \n42170   Stress-related mucosal damage is an erosive pr...  \n104449  Damage to smooth muscle has been the primary c...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pubid</th>\n      <th>question</th>\n      <th>context</th>\n      <th>long_answer</th>\n      <th>final_decision</th>\n      <th>full_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>141060</th>\n      <td>23356518</td>\n      <td>Do magnolia polyphenols attenuate oxidative an...</td>\n      <td>{'contexts': ['The bark of magnolia has been u...</td>\n      <td>This study highlights the important role of NA...</td>\n      <td>yes</td>\n      <td>The bark of magnolia has been used in Oriental...</td>\n    </tr>\n    <tr>\n      <th>101826</th>\n      <td>25476117</td>\n      <td>Are olfactory identification deficits at ident...</td>\n      <td>{'contexts': ['We have previously reported tha...</td>\n      <td>These results suggest that impaired OI is not ...</td>\n      <td>yes</td>\n      <td>We have previously reported that olfactory ide...</td>\n    </tr>\n    <tr>\n      <th>39223</th>\n      <td>18289138</td>\n      <td>Are no differences seen in the regional cerebr...</td>\n      <td>{'contexts': ['Anorexia nervosa (AN) is subdiv...</td>\n      <td>Abnormalities of the neuronal circuits contain...</td>\n      <td>yes</td>\n      <td>Anorexia nervosa (AN) is subdivided into the r...</td>\n    </tr>\n    <tr>\n      <th>42170</th>\n      <td>21725797</td>\n      <td>Does proton pump inhibitor prophylaxis increas...</td>\n      <td>{'contexts': ['Stress-related mucosal damage i...</td>\n      <td>The use of a PPI as a prophylactic treatment a...</td>\n      <td>yes</td>\n      <td>Stress-related mucosal damage is an erosive pr...</td>\n    </tr>\n    <tr>\n      <th>104449</th>\n      <td>23731765</td>\n      <td>Does smooth muscle cell transplantation improv...</td>\n      <td>{'contexts': ['Damage to smooth muscle has bee...</td>\n      <td>During the 2-week follow-up period after trans...</td>\n      <td>yes</td>\n      <td>Damage to smooth muscle has been the primary c...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"# Chunking","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import AutoTokenizer\n\n# 1. Setup the Tokenizer (Using a fast standard one, or use your Llama tokenizer)\ntokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-m3\")\n\n# 2. Define the Chunking Function\ndef chunk_text_to_df(input_df, text_col='full_text', id_col='pubid', chunk_size=256, overlap=32):\n    all_chunks = []\n    \n    # Calculate the stride (how many tokens to move forward)\n    stride = chunk_size - overlap\n    \n    print(f\"Processing {len(input_df)} documents...\")\n    \n    for index, row in input_df.iterrows():\n        doc_id = row[id_col]\n        text = row[text_col]\n        \n        # Tokenize the entire text (return tensors='pt' is slower for loops, standard lists are fine here)\n        tokens = tokenizer.encode(text, add_special_tokens=False)\n        \n        # Create sliding window chunks\n        chunk_index = 0\n        for i in range(0, len(tokens), stride):\n            # Define the slice range\n            chunk_tokens = tokens[i : i + chunk_size]\n            \n            # Decode back to text\n            chunk_text = tokenizer.decode(chunk_tokens)\n            \n            # Create the unique chunk ID (e.g., doc_42_chunk_00)\n            chunk_id = f\"{doc_id}_chunk_{chunk_index:02d}\"\n            \n            # Append to list\n            all_chunks.append({\n                \"chunk_id\": chunk_id,\n                \"document_id\": doc_id,\n                \"chunk_index\": chunk_index,\n                \"chunk_text\": chunk_text\n            })\n            \n            chunk_index += 1\n            \n            # Stop if this was the last chunk (handling exact edge cases)\n            if i + chunk_size >= len(tokens):\n                break\n                \n    # Create the final DataFrame\n    return pd.DataFrame(all_chunks)\n\n# 3. Apply it to your existing 'train_set'\n# Ensure your train_set has 'full_text' and a unique ID column (like 'pubid')\n# If you don't have an ID column, create one first: train_set['pubid'] = train_set.index\n\nchunk_df = chunk_text_to_df(\n    train_set, \n    text_col='full_text', \n    id_col='pubid',  # Replace with your actual ID column name\n    chunk_size=256, \n    overlap=32\n)\n\n# 4. View the Result\nprint(chunk_df.head())\nprint(f\"Total chunks generated: {len(chunk_df)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save the chunked data to disk/working directory as HF Dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_from_disk\nfrom datasets import Dataset\nhf_chunk_df=Dataset.from_pandas(chunk_df)\n\n# 1. Save the dataset to the output directory\nsave_path = \"./chunked_data_v1\"\nhf_chunk_df.save_to_disk(save_path)\n\nprint(f\"✅ Dataset saved successfully to {save_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Zip the chunk table folder","metadata":{}},{"cell_type":"code","source":"!zip -r PubMED_RAG_chunk_table.zip chunked_data_v1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load the saved chunk tabe as a HF Dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_from_disk\nimport os\n\nsave_path = \"/kaggle/input/pubmed-rag/chunked_data_v1\"\n\n# Check if file exists first to avoid errors\nif os.path.exists(save_path):\n    # Load it directly from disk (takes milliseconds)\n    hf_chunked_df = load_from_disk(save_path)\n    print(\"✅ Loaded dataset from disk!\")\n    \n    # Verify it looks right\n    print(hf_chunked_df)\nelse:\n    print(\"⚠️ No saved dataset found. You need to run the chunking code first.\")\n\nchunked_df=hf_chunked_df.to_pandas()\n\nprint(\"The dataframe looks like this: \")\nprint(chunked_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T06:35:42.544913Z","iopub.execute_input":"2026-01-06T06:35:42.545127Z","iopub.status.idle":"2026-01-06T06:35:53.093708Z","shell.execute_reply.started":"2026-01-06T06:35:42.545106Z","shell.execute_reply":"2026-01-06T06:35:53.092918Z"}},"outputs":[{"name":"stdout","text":"✅ Loaded dataset from disk!\nDataset({\n    features: ['chunk_id', 'document_id', 'chunk_index', 'chunk_text'],\n    num_rows: 421148\n})\nThe dataframe looks like this: \n                 chunk_id  document_id  chunk_index  \\\n0       23356518_chunk_00     23356518            0   \n1       23356518_chunk_01     23356518            1   \n2       23356518_chunk_02     23356518            2   \n3       25476117_chunk_00     25476117            0   \n4       25476117_chunk_01     25476117            1   \n...                   ...          ...          ...   \n421143  27011950_chunk_00     27011950            0   \n421144  20463894_chunk_00     20463894            0   \n421145  20463894_chunk_01     20463894            1   \n421146  19663554_chunk_00     19663554            0   \n421147  19663554_chunk_01     19663554            1   \n\n                                               chunk_text  \n0       The bark of magnolia has been used in Oriental...  \n1       (DHE) was used to assay superoxide production ...  \n2       ted IFNγ±LPS-induced iNOS expression, NO, and ...  \n3       We have previously reported that olfactory ide...  \n4       up between individuals with a diagnosis of sch...  \n...                                                   ...  \n421143  The goal of this study was to compare associat...  \n421144  Fusion of placental villous cytotrophoblasts w...  \n421145  control. Furthermore, caveolin-1 knockdown alo...  \n421146  Microelectrode recording (MER) and macrostimul...  \n421147  placement, Wilcoxon signed-rank tests were app...  \n\n[421148 rows x 4 columns]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Reset Index to freeze chunk order","metadata":{}},{"cell_type":"code","source":"chunk_df=chunked_df.reset_index(drop=True)\nprint(f\"frozen datafram: \\n{chunked_df}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T06:35:53.097270Z","iopub.execute_input":"2026-01-06T06:35:53.097533Z","iopub.status.idle":"2026-01-06T06:35:53.122655Z","shell.execute_reply.started":"2026-01-06T06:35:53.097509Z","shell.execute_reply":"2026-01-06T06:35:53.122000Z"}},"outputs":[{"name":"stdout","text":"frozen datafram: \n                 chunk_id  document_id  chunk_index  \\\n0       23356518_chunk_00     23356518            0   \n1       23356518_chunk_01     23356518            1   \n2       23356518_chunk_02     23356518            2   \n3       25476117_chunk_00     25476117            0   \n4       25476117_chunk_01     25476117            1   \n...                   ...          ...          ...   \n421143  27011950_chunk_00     27011950            0   \n421144  20463894_chunk_00     20463894            0   \n421145  20463894_chunk_01     20463894            1   \n421146  19663554_chunk_00     19663554            0   \n421147  19663554_chunk_01     19663554            1   \n\n                                               chunk_text  \n0       The bark of magnolia has been used in Oriental...  \n1       (DHE) was used to assay superoxide production ...  \n2       ted IFNγ±LPS-induced iNOS expression, NO, and ...  \n3       We have previously reported that olfactory ide...  \n4       up between individuals with a diagnosis of sch...  \n...                                                   ...  \n421143  The goal of this study was to compare associat...  \n421144  Fusion of placental villous cytotrophoblasts w...  \n421145  control. Furthermore, caveolin-1 knockdown alo...  \n421146  Microelectrode recording (MER) and macrostimul...  \n421147  placement, Wilcoxon signed-rank tests were app...  \n\n[421148 rows x 4 columns]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Build the Dense Retrieval Class","metadata":{}},{"cell_type":"markdown","source":"## Define the class structure","metadata":{}},{"cell_type":"code","source":"class DenseRetrievalKnowledgeBase:\n    def __init__(self, chunked_df):\n        \n        self.chunked_df=chunked_df\n        self.metadata=chunked_df.to_dict(\"records\")\n        self.embeddings=None\n        self.index=None\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T06:36:08.730456Z","iopub.execute_input":"2026-01-06T06:36:08.730792Z","iopub.status.idle":"2026-01-06T06:36:08.735089Z","shell.execute_reply.started":"2026-01-06T06:36:08.730732Z","shell.execute_reply":"2026-01-06T06:36:08.734260Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"* self.metadata is a list of dictionaries that looks like this:\n [\n  {\n    \"chunk_id\": \"doc_01_chunk_00\",\n    \"document_id\": \"doc_01\",\n    \"chunk_index\": 0,\n    \"chunk_text\": \"Aspirin reduces inflammation...\"\n  },\n  {\n    \"chunk_id\": \"doc_01_chunk_01\",\n    \"document_id\": \"doc_01\",\n    \"chunk_index\": 1,\n    \"chunk_text\": \"COX inhibition mechanisms...\"\n  },\n  {\n    \"chunk_id\": \"doc_02_chunk_00\",\n    \"document_id\": \"doc_02\",\n    \"chunk_index\": 0,\n    \"chunk_text\": \"Colorectal cancer risk...\"\n  }\n\n* Each element of the list is a dictionary that contains the corresponding chunk_id, doc_id, chunk_index and chunk_text.\n\n* The ith chunk reprsents the ith embedding in the FAISS vectorDB.\n\n* This metadata list heps to map the embeddings to the actual text and chunk data\n","metadata":{}},{"cell_type":"markdown","source":"## Create the class object","metadata":{}},{"cell_type":"code","source":"dense_kb=DenseRetrievalKnowledgeBase(chunked_df)\n\nprint(len(dense_kb.metadata))\nprint(dense_kb.metadata[0].keys())\nprint(dense_kb.metadata[0][\"chunk_text\"][:200])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T06:36:12.492032Z","iopub.execute_input":"2026-01-06T06:36:12.492527Z","iopub.status.idle":"2026-01-06T06:36:13.277683Z","shell.execute_reply.started":"2026-01-06T06:36:12.492498Z","shell.execute_reply":"2026-01-06T06:36:13.277078Z"}},"outputs":[{"name":"stdout","text":"421148\ndict_keys(['chunk_id', 'document_id', 'chunk_index', 'chunk_text'])\nThe bark of magnolia has been used in Oriental medicine to treat a variety of remedies, including some neurological disorders. Magnolol (Mag) and honokiol (Hon) are isomers of polyphenolic compounds f\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Load Embedding Model","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\n\nmodel_name=\"BAAI/bge-m3\"\ndense_model=SentenceTransformer(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T06:36:18.403156Z","iopub.execute_input":"2026-01-06T06:36:18.403874Z","iopub.status.idle":"2026-01-06T06:37:03.988728Z","shell.execute_reply.started":"2026-01-06T06:36:18.403842Z","shell.execute_reply":"2026-01-06T06:37:03.987718Z"}},"outputs":[{"name":"stderr","text":"2026-01-06 06:36:27.691175: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767681387.886319      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767681387.941515      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767681388.413248      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767681388.413284      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767681388.413287      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767681388.413289      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d7beec4247f41d4a90672e79e2343ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/123 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"352f0b87a35a423496a70887c53383ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f00447c30ef42f3817507ddfbbf7185"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19f79f56ec6e4cda807da3bade9fafd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/687 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7aa2c0418ff94e81873d150a4e1fcb75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.27G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4f3bb333a8c460d80a9b625219c93a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.27G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73ae6127f1af42489f0931c1f5c3c707"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/444 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72caf3a09e0246ceae981803562ecae8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4feed00b6d54728af1fe3a6f7ac1bf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdb4e8d616b4458095272b2004f42b3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34082e39a594430ba0cd22c82d0b04e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9df69e53a2d4460d8e9fdcaa7ed60bb0"}},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## Prepare to load the chunks into emebdding model","metadata":{}},{"cell_type":"markdown","source":"Save all the chunk texts in a list","metadata":{}},{"cell_type":"code","source":"chunk_texts=[m[\"chunk_text\"] for m in dense_kb.metadata]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T06:37:41.655794Z","iopub.execute_input":"2026-01-06T06:37:41.656536Z","iopub.status.idle":"2026-01-06T06:37:41.720432Z","shell.execute_reply.started":"2026-01-06T06:37:41.656505Z","shell.execute_reply":"2026-01-06T06:37:41.719666Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"Embed the texts","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer\n\n# 1. Setup & Check Hardware\n# ---------------------------------------------------------\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nprint(f\"Number of GPUs: {torch.cuda.device_count()}\")\n\nif torch.cuda.device_count() < 2:\n    print(\"⚠️ Warning: Less than 2 GPUs detected. Multi-process might not yield speedups.\")\n\n# 2. Start Pool\n# ---------------------------------------------------------\n# Ensure model is fresh or on CPU before pooling\n# dense_model = SentenceTransformer('your-model-name') \n\n# Start the pool\npool = dense_model.start_multi_process_pool()\nprint(\"Multi-GPU pool started successfully.\")\n\ntry:\n    # 3. Encode\n    # ---------------------------------------------------------\n    # chunk_texts should be a simple list of strings\n    dense_embeddings = dense_model.encode_multi_process(\n        sentences=chunk_texts,\n        pool=pool,\n        batch_size=128, # 128 is usually safe for T4s (16GB VRAM). If OOM, drop to 64.\n        show_progress_bar=True\n    )\nfinally:\n    # 4. Stop Pool (Wrapped in try/finally to ensure it closes)\n    # ---------------------------------------------------------\n    dense_model.stop_multi_process_pool(pool)\n    print(\"Multi-GPU pool stopped.\")\n\n# 5. Manual Normalization\n# ---------------------------------------------------------\nprint(\"Normalizing embeddings...\")\n\n# L2 Norm: SQRT( sum(x^2) )\n# We use keepdims=True to broadcast the division properly across the (N, 768) shape\nnorms = np.linalg.norm(dense_embeddings, axis=1, keepdims=True)\n\n# Divide by norm to get unit vectors. \n# Clip the small norms to avoid division by zero errors for empty strings.\ndense_embeddings = dense_embeddings / np.clip(norms, 1e-12, None)\n\nprint(f\"Final normalized shape: {dense_embeddings.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T06:49:34.467611Z","iopub.execute_input":"2026-01-06T06:49:34.468366Z","iopub.status.idle":"2026-01-06T09:13:37.792980Z","shell.execute_reply.started":"2026-01-06T06:49:34.468333Z","shell.execute_reply":"2026-01-06T09:13:37.792291Z"}},"outputs":[{"name":"stdout","text":"CUDA available: True\nNumber of GPUs: 2\n","output_type":"stream"},{"name":"stderr","text":"2026-01-06 06:49:40.386465: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767682180.407541     209 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767682180.414018     209 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767682180.430695     209 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767682180.430720     209 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767682180.430723     209 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767682180.430725     209 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n2026-01-06 06:49:49.652909: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767682189.674060     229 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767682189.680444     229 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767682189.696453     229 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767682189.696479     229 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767682189.696481     229 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767682189.696484     229 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"Multi-GPU pool started successfully.\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/2046918738.py:26: DeprecationWarning: The `encode_multi_process` method has been deprecated, and its functionality has been integrated into `encode`. You can now call `encode` with the same parameters to achieve multi-process encoding.\n  dense_embeddings = dense_model.encode_multi_process(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Chunks:   0%|          | 0/85 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3c0046f66074148bc4b5f22fb50df05"}},"metadata":{}},{"name":"stdout","text":"Multi-GPU pool stopped.\nNormalizing embeddings...\nFinal normalized shape: (421148, 1024)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"dense_embeddings = dense_model.encode(\n    chunk_texts,\n    batch_size=64,\n    show_progress_bar=True,\n    convert_to_numpy=True,\n    normalize_embeddings=True\n)\n","metadata":{"execution":{"iopub.status.busy":"2026-01-06T06:38:17.119436Z","iopub.execute_input":"2026-01-06T06:38:17.119762Z","iopub.status.idle":"2026-01-06T06:40:06.569054Z","shell.execute_reply.started":"2026-01-06T06:38:17.119717Z","shell.execute_reply":"2026-01-06T06:40:06.568105Z"}}},{"cell_type":"markdown","source":"## Save the embeddings along with its corresponding chunk","metadata":{}},{"cell_type":"code","source":"import pickle\n\n# 1. Create a data structure (List of dictionaries is common for RAG)\ndata_to_save = {\n    \"texts\": chunk_texts,          # The list of strings you encoded\n    \"embeddings\": dense_embeddings # The numpy array\n}\n\n# 2. Save to a pickle file\nwith open('rag_data.pkl', 'wb') as f:\n    pickle.dump(data_to_save, f)\n\nprint(\"Saved 'rag_data.pkl' successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T09:53:04.032885Z","iopub.execute_input":"2026-01-06T09:53:04.033432Z","iopub.status.idle":"2026-01-06T09:53:06.707471Z","shell.execute_reply.started":"2026-01-06T09:53:04.033394Z","shell.execute_reply":"2026-01-06T09:53:06.706692Z"}},"outputs":[{"name":"stdout","text":"Saved 'rag_data.pkl' successfully.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"!zip rag_data.zip rag_data.pkl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T09:54:19.242061Z","iopub.execute_input":"2026-01-06T09:54:19.242968Z","iopub.status.idle":"2026-01-06T09:56:06.286334Z","shell.execute_reply.started":"2026-01-06T09:54:19.242926Z","shell.execute_reply":"2026-01-06T09:56:06.285402Z"}},"outputs":[{"name":"stdout","text":"  adding: rag_data.pkl","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":" (deflated 17%)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## Load the saved embeddings\nFrom now on to use the embeddings we can use the embeddings from the input PubMed RAG dataset\n* The dataset looks like this:  \n  \n{\n      \n\n    \"texts\":  [ \"text_chunk_0\", \"text_chunk_1\", ... \"text_chunk_N\" ],\n    \n    \"embeddings\":  [[ 0.12, -0.45, ... ],  # Vector for chunk_0\n                    [ 0.88,  0.02, ... ],  # Vector for chunk_1\n                    ...\n                    [ 0.05,  0.11, ... ]]  # Vector for chunk_N\n}","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}